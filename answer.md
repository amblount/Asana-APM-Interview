1. What's the first feature you would build to test this assumption, and why? Clearly define your goals and your target users, and share your brainstorming list of alternates considered

I would build an emotional response tracker using a color picker and a shape mapper. The reason that this would be the first feature that I would build is
becuase, it is important to collect data in order to create a genuine user interaction. I am making the assumption that the user
is already a podcast listener and has specific content which they enjoy engaging with. The reason they would also enjoy the 
user interaction would be to create more of a community around the content they are already engaging with. I am also assuming that
the user is multitasking while listening to the content so their engagement level with the platform is limited, and we want to 
mazimize the amount of information we can get from the user while they are using the screen. The final assumption we are making is that the
user is listening to the content via their mobile device.


2. How does it look and behave? (hint: wireframes are helpful)
![alt text](https://github.com/amblount/Asana-APM-Interview/blob/master/sticher-%20shapes.jpg)

The user can see the color bar, and scroll over the color bar, to change the mood they are feeling while the podcast is playing.
They can also select certain shapes which correspond to a certain mood while they are listening to the content. Because shape selection
only involves one button it makes it really fast and easy for the user to interact with the platform. I could be diffifult for the user to
remember the shape to feeling map, but I would build a side widget component which could pop in and out with the appropirate map.

Althought this feature does not involve direct user interaction, I thought about the ways in which users are currently interacting with
the platform and the ways in which it would be convenient to improve this process, from the user perspective. This would be the first feature
that I would build in order to collect data. After enough users have attached their feeling map to the content at the apporpraite time
stamps we can tell how users are feeling about the content and start discussion boards based on that data. People interacting after the
content has been viewed and they understand how others feel about the content can help them gain a new perspective about their own personal
feelings about the content. With all of this aggregate data we can start to create user maps, and categorization based on the emotions tied
to certain points in the content. For instance if many people placed a circle next on the content screen when the subject m,atter was
doughnuts, we might assume that people are sad about doughnuts, if circle mapped to sad, and we could create a prommpt talking about this.
We could also share this information with the content creator who may find this information useful and think about creating more content
based on these insights.


3. Discuss tradeoffs, risks, and metrics for success. Are there times when the feature would be used a lot but it is still not a success?

By initially focusing on data collection for a more personalized user interaction experience, in the meantime the user is not gaining more
insights from other users, but they are gaining more personal insights about themselves and the ways in which they prefer to interact with
the content. This could be a risky feature to invest a lot of time in because users may not like the way this feature is implemented and
may not understand the purpose of the feature, so they may not use it. I thought a lot about the current use case, or the way that people are
currently listening to audio content, and from the 3 interviews which I conducted most people use it as background noise while they do something
else. That information was really important for me when thinking about how to implement a new feature, it could not be too complicated because the
user does not have much time in which they are interacting with the screen, and/ or interacting with the screen with sticher being the primary
application in use. 

Given the current logo widgets pictures on some of the images included in the google drive, it looks like there are driver mode and 
facebook integration. This is a great start for collecting data, like the time of day the user is opening the app, and how long they are
using it. It could be useful to store data about how long the user is going between opening the app and starting to play the media and then
touching the screen again.
